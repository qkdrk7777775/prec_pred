{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:34:13.783902Z",
     "iopub.status.busy": "2020-11-26T09:34:13.783842Z",
     "iopub.status.idle": "2020-11-26T09:34:16.491709Z",
     "shell.execute_reply": "2020-11-26T09:34:16.491645Z",
     "shell.execute_reply.started": "2020-11-26T09:34:13.783884Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import model_selection\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from numpy import genfromtxt\n",
    "import datatable as dt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:34:20.784719Z",
     "iopub.status.busy": "2020-11-26T09:34:20.784629Z",
     "iopub.status.idle": "2020-11-26T09:34:20.785153Z",
     "shell.execute_reply": "2020-11-26T09:34:20.785089Z",
     "shell.execute_reply.started": "2020-11-26T09:34:20.784689Z"
    }
   },
   "outputs": [],
   "source": [
    "inputDate='2019-01-03 01:00:00'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:34:37.784143Z",
     "iopub.status.busy": "2020-11-26T09:34:37.783998Z",
     "iopub.status.idle": "2020-11-26T09:34:37.785069Z",
     "shell.execute_reply": "2020-11-26T09:34:37.784992Z",
     "shell.execute_reply.started": "2020-11-26T09:34:37.784119Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_load(inputDate,variable=['temp','prec'],path=r'/hdd/temp/',nrow=1159,ncol=1505):\n",
    "    df=np.empty((nrow,ncol,len(variable)),dtype=float)\n",
    "    for k,var in enumerate(variable):\n",
    "        data=dt.fread(f'{path}/{var}{str(inputDate)}.csv')\n",
    "        df[:,:,k]=data.to_numpy().reshape(nrow,ncol)[::-1,::]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:34:42.796514Z",
     "iopub.status.busy": "2020-11-26T09:34:42.796374Z",
     "iopub.status.idle": "2020-11-26T09:34:42.801962Z",
     "shell.execute_reply": "2020-11-26T09:34:42.801724Z",
     "shell.execute_reply.started": "2020-11-26T09:34:42.796491Z"
    }
   },
   "outputs": [],
   "source": [
    "def data_gen(inputDate,shape,DateRange=pd.to_timedelta(1,unit='day')):\n",
    "    generateDate=[str(i) for i in \\\n",
    "                  pd.date_range(start=pd.to_datetime(inputDate)-\\\n",
    "                                DateRange,end=inputDate , freq='H')]\n",
    "    df=np.empty(shape,dtype=float)\n",
    "    for l, td in enumerate(generateDate):\n",
    "        df[l,:,:,:]=data_load(inputDate)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:34:58.788782Z",
     "iopub.status.busy": "2020-11-26T09:34:58.788636Z",
     "iopub.status.idle": "2020-11-26T09:34:58.792230Z",
     "shell.execute_reply": "2020-11-26T09:34:58.792097Z",
     "shell.execute_reply.started": "2020-11-26T09:34:58.788759Z"
    }
   },
   "outputs": [],
   "source": [
    "DateRange=pd.to_timedelta(1,unit='day')\n",
    "generateDate=[str(i) for i in pd.date_range(start=pd.to_datetime(inputDate)-DateRange,end=inputDate , freq='H')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:03.785286Z",
     "iopub.status.busy": "2020-11-26T09:35:03.785110Z",
     "iopub.status.idle": "2020-11-26T09:35:03.787558Z",
     "shell.execute_reply": "2020-11-26T09:35:03.787439Z",
     "shell.execute_reply.started": "2020-11-26T09:35:03.785261Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dates, test=False):\n",
    "        self.test = test\n",
    "#         self.dates=dates\n",
    "        self.dataDate=pd.DataFrame(dates)\n",
    "    def __len__(self):\n",
    "        return len(self.dataDate)\n",
    "\n",
    "    def __getitem__(self, idx,nrow=1159,ncol=1505,variable=['temp','prec']):\n",
    "        date = self.dataDate.T.to_dict('index')[0][idx]\n",
    "        data = data_gen(date,shape=(25,1159,1505,len(variable)))\n",
    "        x = data[:-1,:,:,:]\n",
    "        x = x.astype(np.float32)\n",
    "        x = torch.tensor(x, dtype=torch.float)\n",
    "        if self.test:\n",
    "            return x\n",
    "        else:\n",
    "            y = df_[-1:,:,:,:]\n",
    "            y = y.astype(np.float32)\n",
    "            y = torch.tensor(y, dtype=torch.float)\n",
    "            y = y.unsqueeze(-1)\n",
    "            return x, y\n",
    "        \n",
    "    def data_load(inputDate,path=r'/hdd/temp/',variable=['temp','prec'],nrow=1159,ncol=1505):\n",
    "        df=np.empty((nrow,ncol,len(variable)),dtype=float)\n",
    "        for k,var in enumerate(variable):\n",
    "            print(inputDate)\n",
    "            data=dt.fread(f'{path}/{var}{str(inputDate)}.csv')\n",
    "            df[:,:,k]=data.to_numpy().reshape(nrow,ncol)[::-1,::]\n",
    "        return df\n",
    "    \n",
    "    def data_gen(inputDate,shape,DateRange=pd.to_timedelta(1,unit='day')):\n",
    "        generateDate=[str(i) for i in pd.date_range(start=pd.to_datetime(inputDate)-DateRange,end=inputDate , freq='H')]\n",
    "        df=np.empty(shape,dtype=float)\n",
    "        for l, td in enumerate(generateDate):\n",
    "            df[l,:,:,:]=data_load(inputDate)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:11.907312Z",
     "iopub.status.busy": "2020-11-26T09:35:11.907216Z",
     "iopub.status.idle": "2020-11-26T09:35:11.908858Z",
     "shell.execute_reply": "2020-11-26T09:35:11.908750Z",
     "shell.execute_reply.started": "2020-11-26T09:35:11.907277Z"
    }
   },
   "outputs": [],
   "source": [
    "class DataModule(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size, test=False, num_workers=4):\n",
    "        super().__init__()\n",
    "        self.test = test\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = 4\n",
    "\n",
    "    def setup(self,generateDate, stage=\"train\"):\n",
    "        if stage == \"train\":\n",
    "            train_paths, val_paths = model_selection.train_test_split(\n",
    "                generateDate, test_size=0.1, shuffle=True\n",
    "            )\n",
    "            self.train_dataset = Dataset(train_paths)\n",
    "            self.val_dataset = Dataset(val_paths)\n",
    "        else:\n",
    "            self.test_dataset = Dataset(generateDate, test=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=2 * self.batch_size,\n",
    "            pin_memory=True,\n",
    "            num_workers=self.num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:17.786149Z",
     "iopub.status.busy": "2020-11-26T09:35:17.785955Z",
     "iopub.status.idle": "2020-11-26T09:35:17.787023Z",
     "shell.execute_reply": "2020-11-26T09:35:17.786931Z",
     "shell.execute_reply.started": "2020-11-26T09:35:17.786124Z"
    }
   },
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:22.593860Z",
     "iopub.status.busy": "2020-11-26T09:35:22.592750Z",
     "iopub.status.idle": "2020-11-26T09:35:22.608460Z",
     "shell.execute_reply": "2020-11-26T09:35:22.607470Z",
     "shell.execute_reply.started": "2020-11-26T09:35:22.59347Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, chs=[4, 64, 128]):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(chs[i], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "        self.conv = nn.Conv2d(128, 512, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = []\n",
    "        for block in self.blocks:\n",
    "            x = block(x)\n",
    "            ftrs.append(x)\n",
    "            x = self.pool(x)\n",
    "        x = self.conv(x)\n",
    "        ftrs.append(x)\n",
    "        return ftrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:26.921867Z",
     "iopub.status.busy": "2020-11-26T09:35:26.921818Z",
     "iopub.status.idle": "2020-11-26T09:35:26.922569Z",
     "shell.execute_reply": "2020-11-26T09:35:26.922531Z",
     "shell.execute_reply.started": "2020-11-26T09:35:26.921852Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, chs=[512, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.tr_convs = nn.ModuleList(\n",
    "            [\n",
    "                nn.ConvTranspose2d(chs[i], chs[i + 1], kernel_size=2, stride=2)\n",
    "                for i in range(len(chs) - 1)\n",
    "            ]\n",
    "        )\n",
    "        self.blocks = nn.ModuleList(\n",
    "            [Block(2 * chs[i + 1], chs[i + 1]) for i in range(len(chs) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, ftrs):\n",
    "        for i, ftr in enumerate(ftrs):\n",
    "            x = self.tr_convs[i](x)\n",
    "            x = torch.cat([ftr, x], dim=1)\n",
    "            x = self.blocks[i](x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:31.961305Z",
     "iopub.status.busy": "2020-11-26T09:35:31.961251Z",
     "iopub.status.idle": "2020-11-26T09:35:31.962469Z",
     "shell.execute_reply": "2020-11-26T09:35:31.962425Z",
     "shell.execute_reply.started": "2020-11-26T09:35:31.961288Z"
    }
   },
   "outputs": [],
   "source": [
    "class Baseline(pl.LightningModule):\n",
    "    def __init__(self, lr=1e-3, enc_chs=[4, 64, 128], dec_chs=[512, 128, 64]):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.encoder = Encoder(enc_chs)\n",
    "        self.decoder = Decoder(dec_chs)\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        ftrs = self.encoder(x)\n",
    "        ftrs = ftrs[::-1]\n",
    "        x = self.decoder(ftrs[0], ftrs[1:])\n",
    "        out = self.out(x)\n",
    "        return out\n",
    "\n",
    "    def shared_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self.shared_step(batch, batch_idx)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        return {\"loss\": loss}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"loss\"] for x in outputs]).mean()\n",
    "        print(f\"Epoch {self.current_epoch} | MAE: {avg_loss}\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:39.105065Z",
     "iopub.status.busy": "2020-11-26T09:35:39.104926Z",
     "iopub.status.idle": "2020-11-26T09:35:39.106867Z",
     "shell.execute_reply": "2020-11-26T09:35:39.106806Z",
     "shell.execute_reply.started": "2020-11-26T09:35:39.105041Z"
    }
   },
   "outputs": [],
   "source": [
    "datamodule = DataModule(batch_size=32)\n",
    "datamodule.setup(generateDate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:44.783760Z",
     "iopub.status.busy": "2020-11-26T09:35:44.783707Z",
     "iopub.status.idle": "2020-11-26T09:35:44.805300Z",
     "shell.execute_reply": "2020-11-26T09:35:44.805221Z",
     "shell.execute_reply.started": "2020-11-26T09:35:44.783742Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Baseline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:35:49.920513Z",
     "iopub.status.busy": "2020-11-26T09:35:49.920353Z",
     "iopub.status.idle": "2020-11-26T09:35:49.964010Z",
     "shell.execute_reply": "2020-11-26T09:35:49.963924Z",
     "shell.execute_reply.started": "2020-11-26T09:35:49.920485Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    gpus=1, max_epochs=10, precision=16, progress_bar_refresh_rate=50, benchmark=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-26T09:36:23.788440Z",
     "iopub.status.busy": "2020-11-26T09:36:23.788370Z",
     "iopub.status.idle": "2020-11-26T09:36:24.574950Z",
     "shell.execute_reply": "2020-11-26T09:36:24.706200Z",
     "shell.execute_reply.started": "2020-11-26T09:36:23.788420Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name      | Type       | Params\n",
      "-----------------------------------------\n",
      "0 | criterion | L1Loss     | 0     \n",
      "1 | encoder   | Encoder    | 666 K \n",
      "2 | decoder   | Decoder    | 664 K \n",
      "3 | out       | Sequential | 577   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation sanity check: 0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "ParserError",
     "evalue": "Caught ParserError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1979, in objects_to_datetime64ns\n    values, tz_parsed = conversion.datetime_to_datetime64(data)\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 200, in pandas._libs.tslibs.conversion.datetime_to_datetime64\nTypeError: Unrecognized value type: <class 'str'>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/xpython_4025623/3210728914.py\", line 11, in __getitem__\n    data = data_gen(date,shape=(25,1159,1505,len(variable)))\n  File \"/tmp/xpython_4025623/464845066.py\", line 3, in data_gen\n    pd.date_range(start=pd.to_datetime(inputDate)-\\\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/util/_decorators.py\", line 208, in wrapper\n    return func(*args, **kwargs)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\", line 796, in to_datetime\n    result = convert_listlike(np.array([arg]), box, format)[0]\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\", line 463, in _convert_listlike_datetimes\n    allow_object=True,\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1984, in objects_to_datetime64ns\n    raise e\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1975, in objects_to_datetime64ns\n    require_iso8601=require_iso8601,\n  File \"pandas/_libs/tslib.pyx\", line 465, in pandas._libs.tslib.array_to_datetime\n  File \"pandas/_libs/tslib.pyx\", line 688, in pandas._libs.tslib.array_to_datetime\n  File \"pandas/_libs/tslib.pyx\", line 822, in pandas._libs.tslib.array_to_datetime_object\n  File \"pandas/_libs/tslib.pyx\", line 813, in pandas._libs.tslib.array_to_datetime_object\n  File \"pandas/_libs/tslibs/parsing.pyx\", line 225, in pandas._libs.tslibs.parsing.parse_datetime_string\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/dateutil/parser/_parser.py\", line 1374, in parse\n    return DEFAULTPARSER.parse(timestr, **kwargs)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/dateutil/parser/_parser.py\", line 649, in parse\n    raise ParserError(\"Unknown string format: %s\", timestr)\ndateutil.parser._parser.ParserError: Unknown string format: i\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "In  \u001b[0;34m[65]\u001b[0m:\nLine \u001b[0;34m1\u001b[0m:     trainer.fit(model, datamodule)\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m, in \u001b[0;32mfit\u001b[0m:\nLine \u001b[0;34m445\u001b[0m:   results = \u001b[36mself\u001b[39;49;00m.accelerator_backend.train()\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m, in \u001b[0;32mtrain\u001b[0m:\nLine \u001b[0;34m64\u001b[0m:    results = \u001b[36mself\u001b[39;49;00m.train_or_test()\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m, in \u001b[0;32mtrain_or_test\u001b[0m:\nLine \u001b[0;34m66\u001b[0m:    results = \u001b[36mself\u001b[39;49;00m.trainer.train()\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m, in \u001b[0;32mtrain\u001b[0m:\nLine \u001b[0;34m467\u001b[0m:   \u001b[36mself\u001b[39;49;00m.run_sanity_check(\u001b[36mself\u001b[39;49;00m.get_model())\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m, in \u001b[0;32mrun_sanity_check\u001b[0m:\nLine \u001b[0;34m659\u001b[0m:   _, eval_results = \u001b[36mself\u001b[39;49;00m.run_evaluation(test_mode=\u001b[34mFalse\u001b[39;49;00m, max_batches=\u001b[36mself\u001b[39;49;00m.num_sanity_val_batches)\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pytorch_lightning/trainer/trainer.py\u001b[0m, in \u001b[0;32mrun_evaluation\u001b[0m:\nLine \u001b[0;34m567\u001b[0m:   \u001b[34mfor\u001b[39;49;00m batch_idx, batch \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(dataloader):\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m, in \u001b[0;32m__next__\u001b[0m:\nLine \u001b[0;34m435\u001b[0m:   data = \u001b[36mself\u001b[39;49;00m._next_data()\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m, in \u001b[0;32m_next_data\u001b[0m:\nLine \u001b[0;34m1085\u001b[0m:  \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._process_data(data)\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m, in \u001b[0;32m_process_data\u001b[0m:\nLine \u001b[0;34m1111\u001b[0m:  data.reraise()\n",
      "File \u001b[0;34m/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/_utils.py\u001b[0m, in \u001b[0;32mreraise\u001b[0m:\nLine \u001b[0;34m428\u001b[0m:   \u001b[34mraise\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.exc_type(msg)\n",
      "\u001b[0;31mParserError\u001b[0m: Caught ParserError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1979, in objects_to_datetime64ns\n    values, tz_parsed = conversion.datetime_to_datetime64(data)\n  File \"pandas/_libs/tslibs/conversion.pyx\", line 200, in pandas._libs.tslibs.conversion.datetime_to_datetime64\nTypeError: Unrecognized value type: <class 'str'>\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/worker.py\", line 198, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/tmp/xpython_4025623/3210728914.py\", line 11, in __getitem__\n    data = data_gen(date,shape=(25,1159,1505,len(variable)))\n  File \"/tmp/xpython_4025623/464845066.py\", line 3, in data_gen\n    pd.date_range(start=pd.to_datetime(inputDate)-\\\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/util/_decorators.py\", line 208, in wrapper\n    return func(*args, **kwargs)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\", line 796, in to_datetime\n    result = convert_listlike(np.array([arg]), box, format)[0]\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/tools/datetimes.py\", line 463, in _convert_listlike_datetimes\n    allow_object=True,\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1984, in objects_to_datetime64ns\n    raise e\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/pandas/core/arrays/datetimes.py\", line 1975, in objects_to_datetime64ns\n    require_iso8601=require_iso8601,\n  File \"pandas/_libs/tslib.pyx\", line 465, in pandas._libs.tslib.array_to_datetime\n  File \"pandas/_libs/tslib.pyx\", line 688, in pandas._libs.tslib.array_to_datetime\n  File \"pandas/_libs/tslib.pyx\", line 822, in pandas._libs.tslib.array_to_datetime_object\n  File \"pandas/_libs/tslib.pyx\", line 813, in pandas._libs.tslib.array_to_datetime_object\n  File \"pandas/_libs/tslibs/parsing.pyx\", line 225, in pandas._libs.tslibs.parsing.parse_datetime_string\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/dateutil/parser/_parser.py\", line 1374, in parse\n    return DEFAULTPARSER.parse(timestr, **kwargs)\n  File \"/root/anaconda3/envs/jupyter/lib/python3.6/site-packages/dateutil/parser/_parser.py\", line 649, in parse\n    raise ParserError(\"Unknown string format: %s\", timestr)\ndateutil.parser._parser.ParserError: Unknown string format: i\n\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "trainer.fit(model, datamodule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xpython",
   "language": "python",
   "name": "xpython"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.6.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
